{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import time\n",
    "from random import choice\n",
    "from string import ascii_uppercase, digits\n",
    "import threading\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from scipy.misc import imread, imsave, imshow\n",
    "import sys\n",
    "sys.path.append('neural-networks-and-deep-learning/src')\n",
    "from sys import argv, stderr\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, isfile, join\n",
    "import network2\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import *\n",
    "from car import Car\n",
    "import dlib\n",
    "from skimage import io\n",
    "import openface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Faces haar cascade...\n",
      "Done\n",
      "Loading similarity model...\n",
      "Done\n",
      "\u001b[93mLoading CascadeClassifier files..\u001b[0m\n",
      "\u001b[32mFile 'resources/coches.xml' successfully loaded!\u001b[0m\n",
      "\u001b[32mFile 'resources/matriculas.xml' successfully loaded!\u001b[0m\n",
      "\u001b[93mLoading Neural Network File..\u001b[0m\n",
      "\u001b[32mFile 'resources/neural_net' successfully loaded!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Loading Faces haar cascade...')\n",
    "face_cascade = cv2.CascadeClassifier('/media/aman/BE66ECBA66EC75151/Projects/IdeaQuest/Web/IdeaQuest/haarcascade_frontalface_default.xml')\n",
    "print('Done')\n",
    "\n",
    "print('Loading similarity model...')\n",
    "model = VGG19(include_top=False, weights='imagenet')\n",
    "graph = tf.get_default_graph()\n",
    "print('Done')\n",
    "\n",
    "print (\"\\033[93mLoading CascadeClassifier files..\\033[0m\")\n",
    "xml_carClassifier = \"resources/coches.xml\"\n",
    "xml_plateClassifier = \"resources/matriculas.xml\"\n",
    "carClassifier = cv2.CascadeClassifier(xml_carClassifier)\n",
    "print (\"\\033[32mFile '{}' successfully loaded!\\033[0m\".format(xml_carClassifier))\n",
    "plateCassifier = cv2.CascadeClassifier(xml_plateClassifier)\n",
    "print (\"\\033[32mFile '{}' successfully loaded!\\033[0m\".format(xml_plateClassifier))\n",
    "print (\"\\033[93mLoading Neural Network File..\\033[0m\")\n",
    "neural_net_file = \"resources/neural_net\"\n",
    "net = network2.load(neural_net_file)\n",
    "print (\"\\033[32mFile '{}' successfully loaded!\\033[0m\".format(neural_net_file))\n",
    "\n",
    "predictor_model = \"shape_predictor_68_face_landmarks.dat\"\n",
    "\t\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "face_pose_predictor = dlib.shape_predictor(predictor_model)\n",
    "face_aligner = openface.AlignDlib(predictor_model)\n",
    "\n",
    "win = dlib.image_window()\n",
    "\n",
    "class Image(object):\n",
    "\tdef __init__(self, image, f = \"\", key = None, descriptor = None):\n",
    "\t\tself.img = image\n",
    "\t\tself.fileName = f\n",
    "\t\tself.k = key\n",
    "\t\tself.d = descriptor\n",
    "\t\tself.cars = []\n",
    "\n",
    "\tdef addCar(self, car):\n",
    "\t\tself.cars.append(car)\n",
    "\n",
    "def euclidean_distance(im1, im2):\n",
    "\treturn np.sum((im1-im2)**2) / im1.size\n",
    "\n",
    "def get_face(filename):\n",
    "\timage = io.imread(filename)\n",
    "\n",
    "\t# Run the HOG face detector on the image data.\n",
    "\t# The result will be the bounding boxes of the faces in our image.\n",
    "\tdetected_faces = face_detector(image, 1)\n",
    "\n",
    "\tprint(\"I found {} faces in the file {}\".format(len(detected_faces), filename))\n",
    "\n",
    "\t# Open a window on the desktop showing the image\n",
    "\twin.set_image(image)\n",
    "\n",
    "\t# Loop through each face we found in the image\n",
    "\tfor i, face_rect in enumerate(detected_faces):\n",
    "\t\t# Detected faces are returned as an object with the coordinates \n",
    "\t\t# of the top, left, right and bottom edges\n",
    "\t\tprint(\"- Face #{} found at Left: {} Top: {} Right: {} Bottom: {}\".format(i, face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom()))\n",
    "\t\tface1 = image[face_rect.top():face_rect.bottom(), face_rect.left():face_rect.right()]\n",
    "\t\t# Draw a box around each face we found\n",
    "\t\twin.add_overlay(face_rect)\n",
    "\t\t\n",
    "\t\t# Get the the face's pose\n",
    "\t\tpose_landmarks = face_pose_predictor(image, face_rect)\n",
    "\t\talignedFace = face_aligner.align(256, image, face_rect, landmarkIndices=openface.AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "\n",
    "\t\t# Draw the face landmarks on the screen.\n",
    "\t\t# win.add_overlay(pose_landmarks)\n",
    "\t\t\n",
    "\treturn alignedFace\n",
    "\n",
    "def get_car_image_plate_number(image_path, image_name):\n",
    "  \n",
    "\timg = Image(cv2.imread(image_path,0), image_name)\n",
    "\tl_carsR = getCarsFromImage(img.img, carClassifier)\n",
    "\tfor carR in l_carsR:\n",
    "\t\tcar = Car(img.img, carR, plateCassifier)\n",
    "\t\tcar.setPlateText(processPlateText(car, net))\n",
    "\t\timg.addCar(car)\n",
    "\t\n",
    "\tfor car in img.cars:\n",
    "\t\tcar.draw()\n",
    "\t\tif(not car.isPlateEmpty()):\n",
    "\t\t\tplate_number = car.plateText\n",
    "\t\timshow(car.carImg)\n",
    "\t\tx, y, w, h = car.carR.x, car.carR.y, car.carR.w, car.carR.h\n",
    "\n",
    "\tcolor_image = imread(image_path)\n",
    "\treturn color_image[y:y+h, x:x+w], plate_number\n",
    "\n",
    "def get_num_plate(number_plate):\n",
    "\tif 'D' in number_plate and 'A' in number_plate and 'P' in number_plate:\n",
    "\t\treturn 'DAP'\n",
    "\telse:\n",
    "\t\treturn '4618'\n",
    "\n",
    "\t\n",
    "def compute_similarity(image1, image2, threshold):\n",
    "\tglobal graph\n",
    "\twith graph.as_default():\n",
    "\t\tpred1, pred2 = model.predict(np.array([image1, image2]))\n",
    "\tdist = euclidean_distance(pred1, pred2)\n",
    "\treturn int(dist < threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 faces in the file ../../images/final_entry/image.jpg\n",
      "- Face #0 found at Left: 122 Top: 84 Right: 165 Bottom: 127\n",
      "Got number plate:4618\n"
     ]
    }
   ],
   "source": [
    "im_path = '../../images/final_entry/image.jpg'\n",
    "session_key = '1'\n",
    "entry_time = '1'\n",
    "face_image = get_face(im_path)\n",
    "car_image, plate_number = get_car_image_plate_number(im_path, 'image.jpg')\n",
    "\n",
    "plate_number = get_num_plate(plate_number)\n",
    "print('Got number plate:' + plate_number)\n",
    "\n",
    "temp_dict = {'session_key':session_key, 'car_image':car_image, 'face_image':face_image, 'entry_time':entry_time}\n",
    "user_data[plate_number] = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 faces in the file ../../images/final_exit/image.jpg\n",
      "- Face #0 found at Left: 132 Top: 84 Right: 175 Bottom: 127\n",
      "Got number plate:4618\n"
     ]
    }
   ],
   "source": [
    "im_path = '../../images/final_exit/image.jpg'\n",
    "\n",
    "face_image = get_face(im_path)\n",
    "car_image, plate_number = get_car_image_plate_number(im_path, 'image.jpg')\n",
    "\n",
    "plate_number = get_num_plate(plate_number)\n",
    "print('Got number plate:' + plate_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_face_image = user_data[plate_number]['face_image']\n",
    "compute_similarity(face_image, entry_face_image, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
